{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212c9af76fa3776f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91c257f1121e02ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-20T16:13:31.876156Z",
     "start_time": "2024-03-20T16:13:31.870333Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533185bcdb212399",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e14e0600d9ae47e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-20T15:51:42.688075Z",
     "start_time": "2024-03-20T15:49:17.574289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/xjbs0s0j72s556nv4_bvymhh0000gn/T/ipykernel_8403/4215835436.py:2: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "path = '995,000_rows.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "real_types = ['political', 'fake', 'satire', 'reliable', 'conspiracy', 'bias', 'junksci']\n",
    "df = df[df['type'].notna() & (df['type'].isin(real_types))]\n",
    "reliable_types = ['reliable', 'political']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed0975a05101f45",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60497200e0c4efe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-20T15:51:57.937537Z",
     "start_time": "2024-03-20T15:51:57.813702Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(df['content'])\n",
    "y = np.array([int(t in reliable_types) for t in df['type'] ])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=27)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e92cff4d2588c",
   "metadata": {},
   "source": [
    "## Simple Baseline Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cdd4bfe435c5",
   "metadata": {},
   "source": [
    "### Random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba7efa6650adfc65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:34:26.966122Z",
     "start_time": "2024-03-21T09:34:26.897972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Uniform Random classifier: 0.5005\n",
      "F1 score of Uniform Random classifier: 0.5010\n"
     ]
    }
   ],
   "source": [
    "uniform_classifier = DummyClassifier(strategy='uniform', random_state=0)\n",
    "uniform_classifier.fit(X_train, y_train)\n",
    "y_pred = uniform_classifier.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "uniform_accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Display the scores\n",
    "print(f\"Accuracy of Uniform Random classifier: {accuracy:.4f}\")\n",
    "print(f\"F1 score of Uniform Random classifier: {f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3896f3c78a77b1",
   "metadata": {},
   "source": [
    "Guessing most frequent label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2724b8a6d36bfc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:34:28.255014Z",
     "start_time": "2024-03-21T09:34:28.204243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Most Frequent classifier: 0.5335\n",
      "F1 score of Most Frequent classifier: 0.3712\n"
     ]
    }
   ],
   "source": [
    "classifier = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Display the scores\n",
    "print(f\"Accuracy of Most Frequent classifier: {accuracy:.4f}\")\n",
    "print(f\"F1 score of Most Frequent classifier: {f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a31f005d697c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
